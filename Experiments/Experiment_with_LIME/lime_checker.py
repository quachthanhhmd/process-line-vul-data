# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z38vIWsmKO_0D6NOXva9qhTBwB-Lv0Qb
"""


from transformers import AutoTokenizer, BertModel, AutoModelForSequenceClassification
import torch
import os
import pandas as pd
from pathlib import Path
import numpy as np
from datasets import load_dataset
from tqdm import tqdm
from lime.lime_text import LimeTextExplainer
import torch.nn.functional as F
import json
from torch.utils.data import DataLoader, Dataset

class TextDataset(Dataset):
    def __init__(self, texts, tokenizer):
        self.texts = texts
        self.tokenizer = tokenizer

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors="pt")
        return inputs

# Updated gpu_predictor function
def gpu_predictor(texts, batch_size=50):
    # Create a dataset and dataloader
    dataset = TextDataset(texts, tokenizer)
    dataloader = DataLoader(dataset, batch_size=batch_size)

    all_predictions = []

    for batch in dataloader:
        # Move input to GPU
        inputs = {k: v.squeeze().to("cuda:0") for k, v in batch.items()}

        # Predict with the model
        with torch.no_grad():
            predictions = model(**inputs)

        # Move predictions to CPU and store
        predictions = predictions.logits.detach().cpu().numpy()
        all_predictions.extend(predictions)

    # Convert all predictions to a numpy array
    all_predictions = np.array(all_predictions)

    # Apply softmax to get probabilities
    probabilities = torch.nn.functional.softmax(torch.FloatTensor(all_predictions), dim=-1).numpy()
    return probabilities

ds = load_dataset("Partha117/RealVul")['test']

explainer = LimeTextExplainer(class_names=['uncertain', 'vulnerable'])

tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')
model = AutoModelForSequenceClassification.from_pretrained('Partha117/RQ3_imbalanced').to("cuda:0")

path = "/scratch/partha9/lime_explanations_imbalanced/"
Path(path).mkdir(exist_ok=True, parents=True)
file_list = os.listdir(path)
json_files = [item for item in file_list if ".json" in item]
for row in tqdm(ds):
    if f"{row['unique_id']}_lime.json" not in json_files:
        try:
            exp = explainer.explain_instance(row['code'], gpu_predictor, num_features=20, num_samples=50)
            exp.save_to_file(os.path.join(path, f"{row['unique_id']}_lime.html"))
            with open(os.path.join(path, f"{row['unique_id']}_lime.json"), "w") as f:
                json.dump(exp.as_list(), f)
        except Exception as ex:
            print(ex)
            print(f"Exception in sample {row['unique_id']}")
